{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "729dd0a6-db21-4cb9-854a-19b6f6f55a28",
   "metadata": {},
   "source": [
    "Introduction\n",
    " "
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b2034a8a-e3d8-4d79-85ba-d3987cf34ae2",
   "metadata": {},
   "source": [
    "Purpose of notebook: Hackathon Womanium Quantinuum (QNLP)\n",
    "\n",
    "Date of development: August 2022\n",
    "\n",
    "Developed by: Tessa Evers\n",
    "\n",
    "Note!: This is a draft, many actions can be improved, please do so!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f711788f-e2cb-498f-a511-f3876db834c9",
   "metadata": {},
   "outputs": [],
   "source": [
    "# pip install pandas\n",
    "# pip install nltk\n",
    "# pip install -U scikit-learn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "40b6d240-0d5e-488b-880e-adbb2959356b",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import packages\n",
    "import numpy as np\n",
    "import nltk\n",
    "# nltk.download('punkt')\n",
    "import pandas as pd\n",
    "import os\n",
    "import nltk\n",
    "import nltk.corpus\n",
    "from nltk.tokenize import word_tokenize\n",
    "from nltk.probability import FreqDist\n",
    "from nltk.tokenize import blankline_tokenize \n",
    "from tqdm.autonotebook import tqdm\n",
    "from nltk.util import bigrams, trigrams, ngrams\n",
    "from sklearn.model_selection import train_test_split"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "ea58d4d3-2ee0-4966-8899-071b54841671",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lambeq import BobcatParser\n",
    "from discopy import grammar"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "id": "fe1b13b9-4956-429a-91ae-dc4d578f6b38",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "/home/jovyan/Tessa\n",
      "/home/jovyan/Quantum-Natural-Language-Processing-with-lambeq---Quantinuum\n"
     ]
    }
   ],
   "source": [
    "#working directory\n",
    "print(os.getcwd())\n",
    "os.chdir('/home/jovyan/Quantum-Natural-Language-Processing-with-lambeq---Quantinuum/')\n",
    "print(os.getcwd())"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "52b4f81c-2566-419c-a813-3a82c2e86e42",
   "metadata": {},
   "source": [
    "## Task 2: Get an overview of the dataset\n",
    "\n",
    "Actions Task 2\n",
    "- familiarise yourself with the dataset\n",
    "- learning objective of the model = write, train, test a simple QNLP model that can detect wether they belong to the same category (both IT, or both Food)(y = 1) or not (y = 0).\n",
    "- preprocessing the data with classical NLTK package for example\n",
    "- split data in training and test sets\n",
    "\n",
    "\n",
    "(FYI: later on we will (1) find a suitable quantum representation (2) check the similarity between the sentences)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "c5e65305-6140-487c-bcb7-db5217f79e28",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Import data Quantinuum\n",
    "df_qn = pd.read_csv('MC1.TXT', sep = \",\", names =[\"themei\", \"themej\", \"y\"])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "8273bc55-560e-47f5-8290-26db487baa11",
   "metadata": {},
   "outputs": [],
   "source": [
    "# The data (pair of sentences) we use to predict y \n",
    "df_qn['sentence_pair'] = df_qn['themei'] + \", \" + df_qn['themej']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "bf21e38e-7c29-46a4-986e-dd695ccfca8f",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<div>\n",
       "<style scoped>\n",
       "    .dataframe tbody tr th:only-of-type {\n",
       "        vertical-align: middle;\n",
       "    }\n",
       "\n",
       "    .dataframe tbody tr th {\n",
       "        vertical-align: top;\n",
       "    }\n",
       "\n",
       "    .dataframe thead th {\n",
       "        text-align: right;\n",
       "    }\n",
       "</style>\n",
       "<table border=\"1\" class=\"dataframe\">\n",
       "  <thead>\n",
       "    <tr style=\"text-align: right;\">\n",
       "      <th></th>\n",
       "      <th>themei</th>\n",
       "      <th>themej</th>\n",
       "      <th>y</th>\n",
       "      <th>sentence_pair</th>\n",
       "    </tr>\n",
       "  </thead>\n",
       "  <tbody>\n",
       "    <tr>\n",
       "      <th>0</th>\n",
       "      <td>cook creates complicated dish</td>\n",
       "      <td>experienced chef prepares complicated dish</td>\n",
       "      <td>1</td>\n",
       "      <td>cook creates complicated dish,  experienced ch...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>1</th>\n",
       "      <td>skilful programmer creates code</td>\n",
       "      <td>devoted hacker writes code</td>\n",
       "      <td>1</td>\n",
       "      <td>skilful programmer creates code,  devoted hack...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>2</th>\n",
       "      <td>skilful cook creates meal</td>\n",
       "      <td>devoted hacker creates complicated code</td>\n",
       "      <td>0</td>\n",
       "      <td>skilful cook creates meal,  devoted hacker cre...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>3</th>\n",
       "      <td>hacker writes code</td>\n",
       "      <td>skilful hacker creates code</td>\n",
       "      <td>1</td>\n",
       "      <td>hacker writes code,  skilful hacker creates code</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>4</th>\n",
       "      <td>devoted hacker writes code</td>\n",
       "      <td>hacker writes complicated code</td>\n",
       "      <td>1</td>\n",
       "      <td>devoted hacker writes code,  hacker writes com...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>...</th>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "      <td>...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>95</th>\n",
       "      <td>skilful programmer writes advanced code</td>\n",
       "      <td>skilful cook prepares meal</td>\n",
       "      <td>0</td>\n",
       "      <td>skilful programmer writes advanced code,  skil...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>96</th>\n",
       "      <td>programmer creates code</td>\n",
       "      <td>chef creates dish</td>\n",
       "      <td>0</td>\n",
       "      <td>programmer creates code,  chef creates dish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>97</th>\n",
       "      <td>hacker creates code</td>\n",
       "      <td>chef prepares dish</td>\n",
       "      <td>0</td>\n",
       "      <td>hacker creates code,  chef prepares dish</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>98</th>\n",
       "      <td>skilful programmer creates complicated code</td>\n",
       "      <td>programmer writes complicated code</td>\n",
       "      <td>1</td>\n",
       "      <td>skilful programmer creates complicated code,  ...</td>\n",
       "    </tr>\n",
       "    <tr>\n",
       "      <th>99</th>\n",
       "      <td>experienced cook creates dish</td>\n",
       "      <td>skilful chef creates dish</td>\n",
       "      <td>1</td>\n",
       "      <td>experienced cook creates dish,  skilful chef c...</td>\n",
       "    </tr>\n",
       "  </tbody>\n",
       "</table>\n",
       "<p>100 rows Ã— 4 columns</p>\n",
       "</div>"
      ],
      "text/plain": [
       "                                         themei  \\\n",
       "0                 cook creates complicated dish   \n",
       "1               skilful programmer creates code   \n",
       "2                     skilful cook creates meal   \n",
       "3                            hacker writes code   \n",
       "4                    devoted hacker writes code   \n",
       "..                                          ...   \n",
       "95      skilful programmer writes advanced code   \n",
       "96                      programmer creates code   \n",
       "97                          hacker creates code   \n",
       "98  skilful programmer creates complicated code   \n",
       "99                experienced cook creates dish   \n",
       "\n",
       "                                         themej  y  \\\n",
       "0    experienced chef prepares complicated dish  1   \n",
       "1                    devoted hacker writes code  1   \n",
       "2       devoted hacker creates complicated code  0   \n",
       "3                   skilful hacker creates code  1   \n",
       "4                hacker writes complicated code  1   \n",
       "..                                          ... ..   \n",
       "95                   skilful cook prepares meal  0   \n",
       "96                            chef creates dish  0   \n",
       "97                           chef prepares dish  0   \n",
       "98           programmer writes complicated code  1   \n",
       "99                    skilful chef creates dish  1   \n",
       "\n",
       "                                        sentence_pair  \n",
       "0   cook creates complicated dish,  experienced ch...  \n",
       "1   skilful programmer creates code,  devoted hack...  \n",
       "2   skilful cook creates meal,  devoted hacker cre...  \n",
       "3    hacker writes code,  skilful hacker creates code  \n",
       "4   devoted hacker writes code,  hacker writes com...  \n",
       "..                                                ...  \n",
       "95  skilful programmer writes advanced code,  skil...  \n",
       "96        programmer creates code,  chef creates dish  \n",
       "97           hacker creates code,  chef prepares dish  \n",
       "98  skilful programmer creates complicated code,  ...  \n",
       "99  experienced cook creates dish,  skilful chef c...  \n",
       "\n",
       "[100 rows x 4 columns]"
      ]
     },
     "execution_count": 7,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "df_qn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "497988cf-6db4-4acf-bcb6-7dee722d4405",
   "metadata": {},
   "outputs": [],
   "source": [
    "## Draft for tokenizing\n",
    "# rows = []\n",
    "# for fr, row in df_qn[['sentence_pair']].iterrows():\n",
    "#     rowa = np.array(word_tokenize(df_qn.loc[fr,'sentence_pair']))\n",
    "#     rowab = ' '.join(map(str,rowa))\n",
    "#     rows.append(rowab)\n",
    "#     # df_qn.loc[fr, 'sentence_pair_tok'] = word_tokenize(df_qn.loc[fr,'sentence_pair'])\n",
    "\n",
    "# df_qn['sentence_pair_tok'] = rows#pd.DataFrame(rows, columns= [\"sentence_pair_tok\"]).copy()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "e6a0c1ee-f564-4a30-96f2-c765b773f88a",
   "metadata": {},
   "source": [
    "## Preprocessing data\n",
    "\n",
    "Actions: \n",
    "- Lemmatize\n",
    "- Tokenize\n",
    "- ..... have a look what else is possible by using for example NLTK!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f64a25f6-f68f-4b31-84a4-c96112f72df6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Tokenizing by seperating the pair and later combining\n",
    "# Open action: create a function of this!\n",
    "rowsi = []\n",
    "rowsj = []\n",
    "for fr, row in df_qn[['themei']].iterrows():\n",
    "    rowai = np.array(word_tokenize(df_qn.loc[fr,'themei']))\n",
    "    rowaj = np.array(word_tokenize(df_qn.loc[fr,'themej']))\n",
    "    rowabi = ' '.join(map(str,rowai))\n",
    "    rowabj = ' '.join(map(str,rowaj))\n",
    "    rowsi.append(rowabi)\n",
    "    rowsj.append(rowabj)\n",
    "\n",
    "df_qn['sentence_pair_toki'] = rowsi \n",
    "df_qn['sentence_pair_tokj'] = rowsj\n",
    "df_qn['sentence_pair_tok'] = df_qn['sentence_pair_toki'] + \", \" + df_qn['sentence_pair_tokj'] "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e14017cc-7e7c-46d8-8be1-33d7607b9f03",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Open action: make sure to take into account the \",\" so ADAPT\n",
    "# Open action: create a function of this!\n",
    "rowsi = []\n",
    "rowsj = []\n",
    "for fr, row in df_qn[['sentence_pair_toki']].iterrows():\n",
    "    bigrami = list(nltk.bigrams(df_qn.loc[fr,'sentence_pair_toki'].split(\" \")))\n",
    "    bigramj = list(nltk.bigrams(df_qn.loc[fr,'sentence_pair_tokj'].split(\" \")))\n",
    "    rowai = np.array(bigrami)\n",
    "    rowaj = np.array(bigramj)\n",
    "    rowabi = ' '.join(map(str,rowai))\n",
    "    rowabj = ' '.join(map(str,rowaj))\n",
    "    rowsi.append(rowabi)\n",
    "    rowsj.append(rowabj)\n",
    "\n",
    "df_qn['sentence_pair_tokbi'] = rowsi \n",
    "df_qn['sentence_pair_tokbj'] = rowsj\n",
    "df_qn['sentence_pair_tokb'] = df_qn['sentence_pair_tokbi'] + \", \" + df_qn['sentence_pair_tokbj'] \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "d1de242f-cf4b-4775-a8b8-eab9260065a7",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qn"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b64e54ba-3377-41af-9e56-8d9bffc90aec",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qn_pair = pd.DataFrame()\n",
    "df_qn_pair['sentence_pair'] = df_qn['sentence_pair']\n",
    "# df_qn_pair['sentence_pair_tok'] = df_qn['sentence_pair_tok']\n",
    "df_qn_pair['y'] = df_qn['y']"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ab8fff2b-a07b-4bd7-8b22-03380df5fd47",
   "metadata": {},
   "outputs": [],
   "source": [
    "df_qn_pair"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "16bf00f4-559f-4eb1-bb50-3a66682d9679",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence = df_qn_pair.loc[0, 'sentence_pair']\n",
    "print(sentence)\n",
    "print(type(sentence))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a203f480-9edb-49d9-b5e9-c78242953279",
   "metadata": {},
   "source": [
    "## How does the data look like?\n",
    "\n",
    "Have a look at the distribution of the words in the different sentences"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1a030e10-3623-4a1c-b366-0049c4fc6c5f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test frequence of words\n",
    "fdist = FreqDist()\n",
    "\n",
    "for word in sentence.split(\" \"):\n",
    "    fdist[word.lower()]+=1\n",
    "    \n",
    "print(fdist)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3b15757f-01b5-4892-bcaf-4052361ea31e",
   "metadata": {},
   "outputs": [],
   "source": [
    "print(sentence)\n",
    "print(fdist['cook'])\n",
    "fdist.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "1bff7638-940e-46a4-8a2c-4ec54f271e10",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test frequence of words\n",
    "fdist_complete = FreqDist()\n",
    "\n",
    "for i, row in df_qn_pair[['sentence_pair_tok']].iterrows():\n",
    "    rowad = df_qn_pair.loc[i,'sentence_pair_tok']\n",
    "    for word in rowad.split(\" \"):\n",
    "        fdist_complete[word.lower()]+=1\n",
    "    \n",
    "print(fdist_complete)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "994e1c60-e7ea-4dde-bf5e-be0944d450f6",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fdist_complete.most_common()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c914c5a7-e50c-4121-95ea-904813ef5694",
   "metadata": {},
   "outputs": [],
   "source": [
    "# test frequence of words\n",
    "fdist_complete_notok = FreqDist()\n",
    "\n",
    "for i, row in df_qn_pair[['sentence_pair']].iterrows():\n",
    "    rowad = df_qn_pair.loc[i,'sentence_pair']\n",
    "    for word in rowad.split(\" \"):\n",
    "        fdist_complete_notok[word.lower()]+=1\n",
    "    \n",
    "print(fdist_complete_notok)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0b084fa1-d33a-4146-a6e8-83b2f3124474",
   "metadata": {
    "tags": []
   },
   "outputs": [],
   "source": [
    "fdist_complete_notok.most_common()"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "49ac7d6e-de9a-499f-b86b-460262124a4e",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Make it ready as input for training the model in furter tasks"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "8dd3b522-b9d2-45b7-914d-bae43d912d1a",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Split the data for training and test purposes\n",
    "X_train, X_test, y_train, y_test = train_test_split(df_qn['sentence_pair'], df_qn['y'], test_size=0.33, random_state=42)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "12567f13-91f4-47b0-98d8-e4d1b7f7aeca",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Task 3: Parse sentences to diagrams\n",
    "\n",
    "* Investigate the readers\n",
    "* Make sure that parsing is done correctly by investigating the Rewriters\n",
    "* Identify a selection process of how to determine which reader will be used"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "9e4896ca-885f-4f25-b91d-02215b735197",
   "metadata": {
    "tags": []
   },
   "source": [
    "## DisCoCat with BobcatParser\n",
    "\n",
    "*explain here* \n",
    "1. how it works \n",
    "2. what are the advantages\n",
    "3. what are the disadvantages\n",
    "4. can we use other parsers?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c502a9c2-7d32-4f07-a196-68f14e165bc6",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parse the sentence and convert it into a string diagram\n",
    "parser = BobcatParser(verbose='suppress')\n",
    "print(parser)\n",
    "print(type(parser))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "8da93d0f-bdd7-47f7-8b54-92467685ff52",
   "metadata": {},
   "outputs": [],
   "source": [
    "sentence"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "0dc1785a-3b68-4f78-8a6f-66498400c814",
   "metadata": {},
   "outputs": [],
   "source": [
    "diagram = parser.sentence2diagram(sentence)\n",
    "print(diagram)\n",
    "print(type(diagram))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b2a3aec7-d6ad-4756-86ff-fe163f03c6f1",
   "metadata": {},
   "outputs": [],
   "source": [
    "#string diagram, given a compositional scheme\n",
    "grammar.draw(diagram, figsize=(11,3), fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "46e161b8-f2d4-4f16-91b4-aeb5a3785945",
   "metadata": {},
   "source": [
    "## Different types of readers"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "b15f32bf-1715-4784-8b83-235cf96ff0f3",
   "metadata": {
    "tags": []
   },
   "source": [
    "## Spiders_reader \n",
    "\n",
    "*explain here* \n",
    "1. how it works \n",
    "2. what are the advantages\n",
    "3. what are the disadvantages\n",
    "4. when to select and when to prefer using another reader\n",
    "\n",
    "First note: the spiders_reader seems much faster (for me specific)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6c3a55be-26b3-4bf1-8f29-cf9e2bf7b8b0",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lambeq import spiders_reader"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "afaaf184-8fcf-4960-ae05-fa9a2d0b331d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create string diagrams based on spiders reader\n",
    "spiders_diagram = spiders_reader.sentence2diagram(sentence)\n",
    "print(spiders_diagram)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "749de321-4115-460b-bab0-5e8b5b3daef5",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Not a pregroup diagram, we can't use grammar.draw()\n",
    "spiders_diagram.draw(figsize=(13,6), fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f1b08196-ebb5-4779-8ec4-ee202349d2c5",
   "metadata": {},
   "source": [
    "## Cups_reader \n",
    "\n",
    "*explain here* \n",
    "1. how it works \n",
    "2. what are the advantages\n",
    "3. what are the disadvantages\n",
    "4. when to select and when to prefer using another reader\n",
    "\n",
    "First note: the cups_reader seems also quite fast"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2288f3b3-64c3-4266-97b5-b139b439ce7a",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lambeq import cups_reader\n",
    "\n",
    "# Create string diagrams based on cups reader\n",
    "cups_diagram = cups_reader.sentence2diagram(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "91927c6c-f757-4794-9e88-682b160bd297",
   "metadata": {},
   "outputs": [],
   "source": [
    "grammar.draw(cups_diagram, figsize=(12,3), fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "42f806a0-c36f-4fbc-b346-30461d9aa819",
   "metadata": {},
   "source": [
    "## Stairs_reader\n",
    "\n",
    "*explain here* \n",
    "1. how it works \n",
    "2. what are the advantages\n",
    "3. what are the disadvantages\n",
    "4. when to select and when to prefer using another reader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "13f5469f-a6bb-47d8-b592-557d36dbefba",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lambeq import stairs_reader\n",
    "\n",
    "stairs_diagram = stairs_reader.sentence2diagram(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f103fc05-e4d4-4613-bcf6-a2e170e9ebd3",
   "metadata": {},
   "outputs": [],
   "source": [
    "stairs_diagram.draw(figsize=(12,5), fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f2a0731d-ed80-49f2-b247-007edb44a6e9",
   "metadata": {},
   "source": [
    "## TreeReader\n",
    "\n",
    "*explain here* \n",
    "1. how it works \n",
    "2. what are the advantages\n",
    "3. what are the disadvantages\n",
    "4. when to select and when to prefer using another reader\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "846e2da3-e563-4aca-a0f9-3d3a92920633",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lambeq import TreeReader\n",
    "\n",
    "reader = TreeReader()\n",
    "tree_diagram = reader.sentence2diagram(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee9b718f-ac58-49e4-88f6-fff0b156aee3",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_diagram.draw(figsize=(12,5), fontsize=12)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "12971389-e5b3-42d3-b6ab-333b797a67d4",
   "metadata": {},
   "outputs": [],
   "source": [
    "from lambeq import TreeReader, TreeReaderMode\n",
    "\n",
    "reader = TreeReader(mode=TreeReaderMode.RULE_ONLY)\n",
    "tree_diagram = reader.sentence2diagram(sentence)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3e3424a3-0e73-4e87-bea3-1200dae846fe",
   "metadata": {},
   "outputs": [],
   "source": [
    "tree_diagram.draw(figsize=(12,5), fontsize=12)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "05dcc771-0d18-4b91-84ff-2112edc388d4",
   "metadata": {},
   "source": [
    "## How do we rewrite the diagrams when connections are wrong?\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "af79878e-ab5c-45e2-b5ec-058516dc4cfc",
   "metadata": {},
   "source": [
    "## Task 4: From diagram to circuit\n",
    "Goal: prepare the quantum circuits for each sentence in your dataset. \n",
    "We use an ansatz that \n",
    "1. Maps each wire to a qubit system.\n",
    "2. Maps each box to a variational quantum circuit.\n",
    "\n",
    "Actions\n",
    "- Use IQPAnsatz\n",
    "- Try different number of qubits\n",
    "- Try differrent ansatz layers\n",
    "- Look if hyperparameter tuning can be use like in classical computing when training classified models f.e.!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "cdcd0f9d-7831-42e3-aa49-a43234d94715",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c06ff690-1b3a-4693-ad46-6c5d9a7eea3a",
   "metadata": {},
   "source": [
    "## Task 5: Define the learning objective\n",
    "Goal: prepare the quantaum circuits for each sentence in your dataset\n",
    "\n",
    "Actions\n",
    "- Use first NumpyModel. How does it work? Can we improve?\n",
    "- What similarity metrics are already available and which do work best to predict the similarity between sentences?\n",
    "- Create a working experiment (recall this from working with Qiskit!)\n",
    "- When the model works well, apply it on a simulator!\n",
    "\n",
    "Note: for more tips look at the assignment description!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6d286894-2f10-44fb-b8f1-1a8f98f1e6df",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "ed188119-4528-4542-987b-c212b2509106",
   "metadata": {},
   "source": [
    "## Task 6: Run your first QNLP experiment\n",
    "\n",
    "Actions\n",
    "\n",
    "Note: for more tips look at the assignment description!"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f195975d-6373-4e02-ac16-4a9e2024541d",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "id": "c3eaa85b-1dc4-4f2a-a71c-11a83e1a8c5f",
   "metadata": {},
   "source": [
    "## Notes / rest"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "e6278178-ddc2-49b7-85cf-e5ac4797a357",
   "metadata": {},
   "outputs": [],
   "source": [
    "# from qiskit import *\n",
    "# from qiskit.visualization import plot_histogram\n",
    "# from qiskit.tools.monitor import job_monitor\n",
    "\n",
    "# bell = QuantumCircuit(2, 2)\n",
    "# bell.h(0)\n",
    "# bell.cx(0, 1)\n",
    "\n",
    "# meas = QuantumCircuit(2, 2)\n",
    "# meas.measure([0,1], [0,1])\n",
    "\n",
    "# backend = BasicAer.get_backend('qasm_simulator')\n",
    "# circ = bell + meas\n",
    "# result = execute(circ, backend, shots=1000).result()\n",
    "# counts  = result.get_counts(circ)\n",
    "# print(counts)\n",
    "\n",
    "# plot_histogram(counts)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6df85717-d64a-4bf9-9952-95f31c847414",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3 [Womanium]",
   "language": "python",
   "name": "python3_womanium_go14xk"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.10"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
